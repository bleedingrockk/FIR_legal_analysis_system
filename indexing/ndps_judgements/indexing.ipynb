{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a072119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello1\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5564f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # loads .env file\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"openai_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e278d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total text length: 215195 characters\n",
      "Found 137 case markers\n",
      "\n",
      "✅ Created 132 chunks\n",
      "\n",
      "First chunk preview:\n",
      "Case: 1, Year: 1990\n",
      "Content preview: 1.\n",
      "1990\n",
      "886/1990\n",
      "1990\n",
      "Kadukkak\n",
      "unnil\n",
      "Appachan\n",
      "& Another\n",
      "vs. Excise\n",
      "Circle\n",
      "Inspector\n",
      "Kerala\n",
      "High court\n",
      "Crl M.C.\n",
      "886/1990\n",
      "Honorable Supreme Court, ultimately\n",
      "came to the conclusion that section 167\n",
      "(2),...\n",
      "\n",
      "✅ Saved chunks to chunks.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "# Read the text file\n",
    "with open('english_only_output.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(f\"Total text length: {len(text)} characters\")\n",
    "\n",
    "# Regex pattern to match case numbers (1-3 digits, not starting with 9xx) followed by year\n",
    "# Pattern: ^(?!9\\d{2})\\d{1,3}\\.?\\s*\\n\\d{4}\\b\n",
    "pattern = r'^(?!9\\d{2})\\d{1,3}\\.?\\s*\\n\\d{4}\\b'\n",
    "\n",
    "# Find all matches and their positions\n",
    "matches = list(re.finditer(pattern, text, re.MULTILINE))\n",
    "\n",
    "print(f\"Found {len(matches)} case markers\")\n",
    "\n",
    "# Create chunks based on the pattern\n",
    "chunks = []\n",
    "for i, match in enumerate(matches):\n",
    "    start_pos = match.start()\n",
    "    # End position is the start of next match, or end of text\n",
    "    end_pos = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "    \n",
    "    chunk_text = text[start_pos:end_pos].strip()\n",
    "    \n",
    "    # Extract case number and year from the match\n",
    "    case_match = match.group(0)\n",
    "    case_num = re.search(r'\\d{1,3}', case_match).group(0) if re.search(r'\\d{1,3}', case_match) else None\n",
    "    year_match = re.search(r'\\d{4}', case_match)\n",
    "    year = year_match.group(0) if year_match else None\n",
    "    \n",
    "    if chunk_text and len(chunk_text) > 50:  # Only include substantial chunks\n",
    "        chunks.append({\n",
    "            'chunk_id': len(chunks),\n",
    "            'case_number': case_num,\n",
    "            'year': year,\n",
    "            'content': chunk_text,\n",
    "            'start_pos': start_pos,\n",
    "            'end_pos': end_pos\n",
    "        })\n",
    "\n",
    "print(f\"\\n✅ Created {len(chunks)} chunks\")\n",
    "if chunks:\n",
    "    print(f\"\\nFirst chunk preview:\")\n",
    "    print(f\"Case: {chunks[0]['case_number']}, Year: {chunks[0]['year']}\")\n",
    "    print(f\"Content preview: {chunks[0]['content'][:200]}...\")\n",
    "\n",
    "# Save chunks to JSON\n",
    "with open('chunks.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(chunks, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n✅ Saved chunks to chunks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a724557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings with OpenAI text-embedding-3-large...\n",
      "✅ Added 132 vectors to Flat index\n",
      "✅ Saved index to legal_index.faiss and chunks to chunks.json\n",
      "\n",
      "✅ FAISS index created successfully!\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from typing import List, Dict\n",
    "import os\n",
    "\n",
    "class NDPSJudgementsFAISSIndex:\n",
    "    def __init__(self, openai_api_key: str):\n",
    "        \"\"\"\n",
    "        Initialize FAISS for NDPS judgements retrieval using OpenAI embeddings (text-embedding-3-large)\n",
    "        \"\"\"\n",
    "        self.embedding_model = OpenAIEmbeddings(\n",
    "            model='text-embedding-3-large',\n",
    "            api_key=openai_api_key,\n",
    "        )\n",
    "        # OpenAI text-embedding-3-large has 3072 dimensions\n",
    "        self.dimension = 3072\n",
    "        self.index = None\n",
    "        self.chunks = []\n",
    "        \n",
    "    def create_index(self, chunks: List[Dict]):\n",
    "        \"\"\"\n",
    "        Create FAISS Flat index for maximum accuracy\n",
    "        \"\"\"\n",
    "        self.chunks = chunks\n",
    "        texts = [chunk['content'] for chunk in chunks]\n",
    "        \n",
    "        # Generate embeddings using OpenAI\n",
    "        print(\"Generating embeddings with OpenAI text-embedding-3-large...\")\n",
    "        embeddings = self.embedding_model.embed_documents(texts)\n",
    "        embeddings = np.array(embeddings).astype('float32')\n",
    "        \n",
    "        # Normalize for cosine similarity\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        \n",
    "        # Use Flat index for maximum accuracy\n",
    "        self.index = faiss.IndexFlatIP(self.dimension)\n",
    "        self.index.add(embeddings)\n",
    "        print(f\"✅ Added {len(embeddings)} vectors to Flat index\")\n",
    "        \n",
    "    def search(self, query: str, k: int = 5):\n",
    "        \"\"\"\n",
    "        Search for relevant judgements\n",
    "        \n",
    "        Args:\n",
    "            query: Legal query or case description\n",
    "            k: Number of results to return\n",
    "        \"\"\"\n",
    "        # Generate query embedding\n",
    "        query_vector = self.embedding_model.embed_query(query)\n",
    "        query_vector = np.array([query_vector]).astype('float32')\n",
    "        faiss.normalize_L2(query_vector)\n",
    "        \n",
    "        # Search\n",
    "        scores, indices = self.index.search(query_vector, k)\n",
    "        \n",
    "        results = []\n",
    "        for idx, score in zip(indices[0], scores[0]):\n",
    "            if idx < len(self.chunks):\n",
    "                result = {\n",
    "                    'chunk': self.chunks[idx],\n",
    "                    'score': float(score)\n",
    "                }\n",
    "                results.append(result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_index(self, index_path: str, chunks_path: str):\n",
    "        \"\"\"Save FAISS index and chunks\"\"\"\n",
    "        faiss.write_index(self.index, index_path)\n",
    "        import json\n",
    "        with open(chunks_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.chunks, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"✅ Saved index to {index_path} and chunks to {chunks_path}\")\n",
    "    \n",
    "    def load_index(self, index_path: str, chunks_path: str):\n",
    "        \"\"\"Load FAISS index and chunks\"\"\"\n",
    "        self.index = faiss.read_index(index_path)\n",
    "        import json\n",
    "        with open(chunks_path, 'r', encoding='utf-8') as f:\n",
    "            self.chunks = json.load(f)\n",
    "        print(f\"✅ Loaded index with {self.index.ntotal} vectors and {len(self.chunks)} chunks\")\n",
    "\n",
    "# Load chunks\n",
    "with open('chunks.json', 'r', encoding='utf-8') as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "# Create and save index\n",
    "indexer = NDPSJudgementsFAISSIndex(OPENAI_API_KEY)\n",
    "indexer.create_index(chunks)\n",
    "indexer.save_index('legal_index.faiss', 'chunks.json')\n",
    "\n",
    "print(f\"\\n✅ FAISS index created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f673970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: bail application in NDPS cases\n",
      "\n",
      "================================================================================\n",
      "✅ Loaded index with 132 vectors and 132 chunks\n",
      "Found 5 relevant results:\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Result 1 (Score: 0.6588)\n",
      "Case Number: 24\n",
      "Year: 2001\n",
      "\n",
      "Content:\n",
      "--------------------------------------------------------------------------------\n",
      "24\n",
      "2001\n",
      "Union of\n",
      "India Vs.\n",
      "Ashok\n",
      "Kumar\n",
      "Jaiswal\n",
      "(2007)15SC\n",
      "C569\n",
      "Supreme Court held that Under the\n",
      "mandatory\n",
      "conditions provided in\n",
      "Section 37 before granting bail the\n",
      "Court is to be satisfied that there are\n",
      "reasonable grounds for believing that\n",
      "the accused is not guilty of offence and\n",
      "that he is not likely to commit offences\n",
      "under the Act while on bail. This Court\n",
      "in various judgments while quashing\n",
      "the orders granting bail to accused of\n",
      "offence under the Act have cautioned\n",
      "the courts about the m\n",
      "...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Result 2 (Score: 0.6484)\n",
      "Case Number: 3\n",
      "Year: 1990\n",
      "\n",
      "Content:\n",
      "--------------------------------------------------------------------------------\n",
      "3.\n",
      "1990\n",
      "Raj\n",
      "Kumar\n",
      "Karwal\n",
      "versus\n",
      "Union of\n",
      "India\n",
      "(1990) 2\n",
      "SCC 409\n",
      "Honorable Supreme Court Has held -\n",
      "Officers of DRI/Customs invested with\n",
      "powers of investigation of offences\n",
      "under S. 53 of the NDPS Act are not\n",
      "Police Officers within the meaning of S.\n",
      "25 of the Indian Evidence Act, as they\n",
      "do not have power to lodge a report\n",
      "under S. 173 of the Cr. P.C .--\n",
      "Confessional statement made to such\n",
      "officers is not hit by S. 25 of the Indian\n",
      "Evidence Act.\n",
      "1991\n",
      "(1991) 1\n",
      "1991\n",
      "Narcotic\n",
      "Control\n",
      "Bureau vs.\n",
      "Kis\n",
      "...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Result 3 (Score: 0.6428)\n",
      "Case Number: 42\n",
      "Year: 2007\n",
      "\n",
      "Content:\n",
      "--------------------------------------------------------------------------------\n",
      "42\n",
      "2007\n",
      "(2007) 7\n",
      "44\n",
      "NARCOTICS CONTROL BUREAU\n",
      "http://narcoticsindia.nic.in\n",
      "\n",
      "=== PAGE 72 ===\n",
      "\n",
      "http://narcoticsindia.nic.in\n",
      "NARCOTICS CONTROL BUREAU\n",
      "45\n",
      "\n",
      "=== PAGE 73 ===\n",
      "\n",
      "2007\n",
      "Union of\n",
      "India Vs.\n",
      "Shri Shiv\n",
      "Shanker\n",
      "Kesari\n",
      "(2007)7SCC\n",
      "798\n",
      "Honourable Supreme Court held that\n",
      "Court while considering the application\n",
      "for bail with reference to Section 37 of\n",
      "the Act is not called upon to record a\n",
      "finding of not guilty. It is for the limited\n",
      "purpose essentially confined to the\n",
      "question of releasing the accused\n",
      "...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Result 4 (Score: 0.6394)\n",
      "Case Number: 6\n",
      "Year: 1995\n",
      "\n",
      "Content:\n",
      "--------------------------------------------------------------------------------\n",
      "6.\n",
      "1995\n",
      "Saiyad\n",
      "Mohd.\n",
      "V/s State\n",
      "1995 CrLJ\n",
      "2662\n",
      "Honorable Supreme Court Has held :It\n",
      "is mandatory for the searching officer\n",
      "to inform the searched person about\n",
      "his right to be searched in the presence\n",
      "of a Magistrate or a Gazetted Officer --\n",
      "No presumption can be made in this\n",
      "regard -- This point can also be raised in\n",
      "Appeal for the first time -- - In the\n",
      "absence of clear evidence that the\n",
      "Officer conducting the search had\n",
      "informed the person to be searched\n",
      "that he was entitled to demand the\n",
      "prese\n",
      "...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Result 5 (Score: 0.6360)\n",
      "Case Number: 37\n",
      "Year: 2005\n",
      "\n",
      "Content:\n",
      "--------------------------------------------------------------------------------\n",
      "37\n",
      "2005\n",
      "2005\n",
      "State of\n",
      "Rajasthan\n",
      "Vs. Ram\n",
      "Chandra,\n",
      "(2005) 5\n",
      "SCC 151\n",
      "Honourable Supreme Court held that\n",
      "Search to be conducted in presence of\n",
      "officers stipulated by law -- All the\n",
      "options were made known to the\n",
      "accused and he himself opted to be\n",
      "searched in the presence of the Deputy\n",
      "Superintendent of Police-as under Sec.\n",
      "50 of NDPS Act fair play and\n",
      "transparency in the process of search\n",
      "has been given the primacy -- The\n",
      "question of prejudice or bias has to be\n",
      "established by the accused and not\n",
      "inf\n",
      "...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test query\n",
    "query = \"bail application in NDPS cases\"\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load index\n",
    "indexer = NDPSJudgementsFAISSIndex(OPENAI_API_KEY)\n",
    "indexer.load_index('legal_index.faiss', 'chunks.json')\n",
    "\n",
    "# Search\n",
    "results = indexer.search(query, k=5)\n",
    "\n",
    "print(f\"Found {len(results)} relevant results:\\n\")\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    chunk = result['chunk']\n",
    "    score = result['score']\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Result {i} (Score: {score:.4f})\")\n",
    "    print(f\"Case Number: {chunk.get('case_number', 'N/A')}\")\n",
    "    print(f\"Year: {chunk.get('year', 'N/A')}\")\n",
    "    print(f\"\\nContent:\")\n",
    "    print(\"-\" * 80)\n",
    "    # Show first 500 characters\n",
    "    content_preview = chunk['content'][:500]\n",
    "    print(content_preview)\n",
    "    if len(chunk['content']) > 500:\n",
    "        print(\"...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67210586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
